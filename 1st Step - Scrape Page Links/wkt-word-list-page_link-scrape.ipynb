{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb0d8a1",
   "metadata": {},
   "source": [
    "## How to Scrape Word List *Page Links* from Wiktionary\n",
    "\n",
    "Probably you wanted to scrape the word lists with BeautifulSoup or Rvest or whatever... You wanted to write a loop, but it seems like every single \"next page\" is a different link. Bummer? Of course not! Just with few steps you can parse the link pages of Wiktionary and we can parse the words with Rvest. \n",
    "\n",
    "**This is the first step of scraping the words. Please see the *scrape-wkt-words.Rmd* file in the repository after this.**\n",
    "\n",
    "- In this tutorial, you will learn how to scrape Wiktionary word list page links.\n",
    "- Wiktionary does not provide a standard link for its pages. \n",
    "- Please read the #Comments carefully to fully understand how this process works.\n",
    "\n",
    "## Before starting...\n",
    "- We'll use Selenium. Which opens a portable browser and does our scraping work automatically.\n",
    "- You'll need to install ChromeDriver (or GeckoDriver if you're using Firefox), I'll use Chrome here.\n",
    "- Here's a tutorial video of how to install these drivers: https://www.youtube.com/watch?v=dz59GsdvUF8\n",
    "- This is where you download ChromeDriver: https://chromedriver.chromium.org/downloads\n",
    "- Make sure you match the ChromeDriver and Chrome Version. To check it, write this in the address bar: chrome://version\n",
    "- You **must** install ChromeDriver (or Geckodriver) before starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26efb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7c1fa",
   "metadata": {},
   "source": [
    "## Important Aspect in Wiktionary\n",
    "\n",
    "Every page has 200 words. You need to decide on the range by the word count. \n",
    "\n",
    "E.g. if it says 'The following 200 pages are in this category, out of 8,979 total.' \n",
    "\n",
    "You will have to divide 8979 to 200 = 44,895\n",
    "\n",
    "That means there are 44 pages to scrape. In the function. You will have to write that down to the code.\n",
    "\n",
    "**Beware:** When you run this code, a Google Chrome browser will pop up. *Don't freak out*, that's what Selenium does. It copies stuff for you automatically through a portable browser. No need to worry. Everything is cool. If you run this cell but a browser just opens and immediately closes, it means that your ChromeDriver is out of date, download the newest version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this tutorial, we'll use the Turkish nouns list.\n",
    "url = 'https://en.wiktionary.org/wiki/Category:Turkish_nouns'\n",
    "PATH = \"C:/Windows/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "\n",
    "\n",
    "# First of all, creating a new list to store our link list\n",
    "page_list = []\n",
    "\n",
    "\n",
    "\n",
    "# Now here's one thing to remember. The code will parse pages starting with the first \"next page\". \n",
    "# So the content in the very first page will not be parsed. We need to add that!\n",
    "page_list.append(url)\n",
    "\n",
    "\n",
    "\n",
    "# This function opens the website, parses the link of every single \"next page\", stores in a list, then clicks on it.\n",
    "def scrapeandclick():\n",
    "    nextpg = driver.find_element(By.XPATH, '//*[@id=\"mw-pages\"]/a[2]')\n",
    "    pagelink = (nextpg.get_attribute('href'))\n",
    "    print(pagelink)\n",
    "    pagelist_item = pagelink\n",
    "    page_list.append(pagelist_item)\n",
    "    nextpg.click()\n",
    "\n",
    "    \n",
    "    \n",
    "# Time to Run Selenium\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "\n",
    "# Now as described in the Markdown, the Turkish nouns list has 8979 total words\n",
    "# As it should be remembered, each page has 200 words. \n",
    "# Let's divide that, 8979/200 = 44,895\n",
    "# As a solution our range is 44\n",
    "\n",
    "for x in range(44):\n",
    "    scrapeandclick()\n",
    "    \n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45055fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how cool your list is\n",
    "page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09af7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Frame with the list\n",
    "\n",
    "df = pd.DataFrame(page_list)\n",
    "df.columns = ['Wiktionary Page Link']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your output to a CSV file for future use\n",
    "\n",
    "df.to_csv(\"wiktionary_page_link.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
